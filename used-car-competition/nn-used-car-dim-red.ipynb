{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_val_score, validation_curve, learning_curve, ValidationCurveDisplay, LearningCurveDisplay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('data/train.parquet')\n",
    "test = pd.read_parquet('data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['price'])\n",
    "y_train = pd.DataFrame(train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sizes_abs, train_scores, test_scores, fit_times, score_times = learning_curve(estimator=mlp, X=X_train, y=y, n_jobs=-1, scoring='neg_mean_squared_error', random_state=11)\n",
    "# display = LearningCurveDisplay(train_sizes=train_sizes_abs, train_scores=train_scores, test_scores=test_scores, score_name=\"Accuracy\")\n",
    "# display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.fit(X=X_train, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=11, random_state=11, whiten=True)\n",
    "X_red = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min number of components required to preserve x % training set variance\n",
    "preserve_var = .9\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum>=preserve_var)+1\n",
    "print(f'{d} components required to preserve {preserve_var*100}% variance')\n",
    "print(cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained = pca.explained_variance_ratio_\n",
    "cumulative_variance_explained = variance_explained.cumsum()\n",
    "bars = plt.bar(range(1, len(variance_explained) + 1), variance_explained, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(1, len(variance_explained) + 1), variance_explained.cumsum(), where='mid', label='Cumulative explained variance')\n",
    "for bar,i in zip(bars,enumerate(bars)):\n",
    "    height = bar.get_height()\n",
    "    if i[0]==0: continue\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.2%}', ha='center', va='bottom')\n",
    "for i, cumulative_variance in enumerate(cumulative_variance_explained, 1):\n",
    "    plt.annotate(f'{cumulative_variance:.2%}',\n",
    "                 xy=(i, cumulative_variance),\n",
    "                 xytext=(0, 3),  # 3 points vertical offset\n",
    "                 textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.title('Scree plot | red wine')\n",
    "plt.xticks(np.arange(pca.n_components_)+1)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, random_state=11, whiten=True)\n",
    "X_pca_train = pca.fit_transform(X_train)\n",
    "# X_pca_test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pd.DataFrame(X_pca_train)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.to_parquet('data/X_pca.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_for_pca = test.drop(columns=['id'])\n",
    "test_for_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=11, random_state=11, whiten=True)\n",
    "X_red = pca.fit_transform(test_for_pca)\n",
    "\n",
    "# min number of components required to preserve x % training set variance\n",
    "preserve_var = .9\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum>=preserve_var)+1\n",
    "print(f'{d} components required to preserve {preserve_var*100}% variance')\n",
    "print(cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, random_state=11, whiten=True)\n",
    "X_pca_test = pca.fit_transform(test_for_pca)\n",
    "# X_pca_test = pca.transform(test)\n",
    "X_pca_test = pd.DataFrame(X_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test['id'] = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test.to_parquet('data/X_pca_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_test.to_csv('data/X_pca_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
